# Smart Node v2.0

Smart Node v2 is a complete rewrite of the Rocket Pool Smart Node that aims to improve existing functionality, add new functionality, and make it dramatically easier to maintain. It incorporates modern tooling and techniques, years of lessons learned from working with the original Smart Node in the wild, and many suggestions provided by users that made sense but just weren't practical to build into v1.

This guide is meant to serve as an introduction to v2 for both developers and node operators alike. It's intended to be a living document, so it will change over time as testing on v2 continues and the release is refined.


## Overview of What's New

The following is a list of what's changed from v1 so far, in no particular order:


### Installation

NOTE: for actual installation instructions, please see the [section below](#installing-v2).

- The Smart Node now comes in a `.deb` package, so users running Debian or Debian-derivative distributions can now install it via `sudo apt install rocketpool` and update it via `sudo apt update && sudo apt dist-upgrade` once the Rocket Pool repository is set up.
    - Packages for other distributions, such as RHEL or Fedora, will be introduced at a later date.
    - For now, users not on Debian-based systems can install via the traditional `rocketpool service install` command. It will still pull the necessary files from GitHub as it did before.
- Installation no longer puts all core system files into your `~/.rocketpool` directory. System files (such as Docker compose templates and execution scripts) are now put into `/usr/share/rocketpool`. The CLI binary is now installed to `/usr/bin/rocketpool`.
    - Runtime files, such as your Docker compose overrides and logging, are still put into `~/.rocketpool` by default.
- Installation via the CLI can optionally now be done with local install scripts and packages on your filesystem instead of needing to reach out to GitHub. This is helpful in places where GitHub can't be accessed.
- (*For developers*) The old `smartnode-install` repository has been migrated into the `smartnode` repository.


### Daemon (Node Container / Service)

- The `api`, `node`, and `watchtower` Docker containers have now all been consolidated into one `node` container.
- The daemon now uses [Multicall](https://github.com/makerdao/multicall) for all of its Execution client reads, batching state reads together into as few requests as possible. This significantly reduces the overhead (both CPU-wise and time-wise) on large operations that required many blockchain reads, such as `minipool status` or the new on-chain Protocol DAO voting system.
- You can now run the node in **passwordless** mode, where the password for your node wallet is not saved to disk. This way, if someone steals your node, they will not have access to your node wallet. *(They can still slash your validators, though).*
    - When using passwordless mode, you'll need to provide the password via the CLI any time you restart the daemon. It will be preserved in memory but not on disk.
- You can now enter **masquerade** mode, where your node assumes an arbitrary address that you specify. For all intents and purposes, your API, node, and watchtower loops will proceed to act like the specified node instead. As you don't have the private key for that address, your node will be in *read-only* mode while masquerading and won't be able to submit transactions or recover validator keys. You can end the masquerade and return to your normal (wallet) address at any time.
    - This is particularly useful for support and debugging.
- The daemon now supports graceful shutdowns of the API server, node, and watchtower task loops rather than terminating them immediately upon closing.


### API

- The daemon API has been overhauled. It is no longer a sequence of terminal commands executed by the CLI via `docker exec`. It has been replaced with a true HTTP-based API endpoint.
    - The API endpoint is hosted on a Unix socket and is accessible by processes running as the user on the node's local filesystem (e.g., the new Smart Node CLI).
    - It is *not* (currently) accessible via a TCP port, so it can't be reached via browser; this is a feature that will be coming in the future but requires the addition of an authentication system first.
    - Once that is in place, the Smart Node will be open to things such as WebUIs to replace (or at least supplement) the CLI.
- The API is now a persistent process; instead of starting and stopping with every CLI command, as in v1, it will now start with the `rocketpool_node` daemon and maintain state until the daemon stops. This means it doesn't need to reacquire all of the network contracts and parse their ABIs with every call; it only does this once at startup, which provides a significant speedup over v1.


### Logging

- The CLI and daemon both now have improved logging systems.
    - The CLI's global `--debug` flag will now print debugging information to the terminal as the relevant command is being executed.
    - The daemon now logs its activities to three separate files:
        - `api.log` for API requests and responses, such as HTTP requests submitted by the CLI (completely new, v1 unfortunately does not have an analog for this)
        - `tasks.log` which records logs from the node's task loop (used to be the standard output of the `rocketpool_node` container)
        - `watchtower.log` which records logs from the watchtower's task loop (used to be the standard output of the `rocketpool_watchtower` container)
    - The daemon's logs can be written in [logfmt](https://www.brandur.org/logfmt) or JSON. They support proper, customizable [log rotation](https://en.wikipedia.org/wiki/Log_rotation) and four log levels ranging from `DEBUG` to `ERROR`.


### Transactions

- In v1, commands that provide multiple selectable options (such as distributing minipool balances) would only allow you to select one option from the list, or "all". In v2, you are now able to select an arbitrary combination of options if you want to trigger the function on some, but not all, of the options.
- In v1, running a command on multiple options would submit the transactions in sequence; the first would submit, then it would wait for it to complete before submitting the next one, and so on. In v2, the Smart Node now submits all transactions at the same time and waits for them in parallel once they've been submitted.
    - This will make multi-tx operations much, much faster and less sensitive to gas fluctuations, as multiple TXs can now be included in the same block together.
    - This also fixes issues where the selected gas price was only applied to the first transaction in v1. In v2, the selected gas price is applied to all transactions.


### CLI Command Changes

- Use `rocketpool -pt ...` to print raw transaction info (such as calldata) without submitting if you want to use the calldata for your own activities.
- Use `rocketpool -st ...` to sign all transactions and print them without submitting them to the network. This is useful for things like offline wallets or creating custom transaction bundles for services like [Flashbots Protect](https://docs.flashbots.net/flashbots-protect/overview).
- Use `rocketpool --debug ...` to print debug info about the command being run, such as API back-and-forth traffic or other variables.
- When using the `rocketpool service config` TUI to modify the Smart Node's configuration, you can now include the `-u` file to intentionally restore all of the settings that will be replaced during a Smart Node upgrade, even if you're not upgrading.
    - This is useful if you manually tweaked container tags and just want to get the "recommended" tags back.
    - This is also useful for development testing where you want to emulate an upgrade when you install a new build, even if the new version is the same as the old version.
- `rocketpool node sync` has been moved to `rocketpool service sync` to more accurately reflect its nature.
- `rocketpool node sign-message` and `rocketpool node send-message` have been moved to `rocketpool wallet sign-message` and `rocketpool wallet send-message` for the same reason.
- Use `rocketpool wallet delete-password` to enter passwordless mode.
- Use `rocketpool wallet set-password` to provide the password to the daemon. You will be prompted for whether or not you want to save it to disk.
- Use `rocketpool wallet masquerade` to set your node's address to someone else.
- Use `rocketpool wallet restore-address` to end masquerading and set your node's address to your wallet address.
- Use `rocketpool service node-logs` with `api`, `tasks`, and/or `watchtower` to view the new logs respectively.


## Installing v2 - Docker and Hybrid Mode

Prior to installation, please note that Smart Node v2 will **only work with the Rocket Pool Houston upgrade**. It will not work with Atlas or any previous Rocket Pool protocol version.

Start by preparing your node:

- [Preparation if migrating from an existing Smart Node v1 installation](#important-migrating-from-smart-node-v1)
- [Preparation if you didn't have an exsisting Smart Node installation](#installing-docker)

Next, install the Smart Node from one of the options below:

- [Install official releases via the Package Manager (for Debian-based systems)](#installing-official-releases-via-the-package-manager)
- [Install via `rocketpool service install` and GitHub (the v1 method)](#installing-via-rocketpool-service-install-and-github)
- [Install via `rocketpool service install` without GitHub access](#installing-via-rocketpool-service-install-without-github)


### **IMPORTANT:** Migrating from Smart Node v1

If you have Smart Node v1 already installed on your machine, you will need to do a little bit of cleanup before installing v2.

First, **back up your existing Rocket Pool directory (`~/.rocketpool` by default)** somewhere safe, just in case. Next, run the following command:
```
rm -rf ~/bin/rocketpool ~/.rocketpool/scripts ~/.rocketpool/templates ~/.rocketpool/prometheus.tmpl
```
This will delete the old v1 CLI and some accompanying installation files that are no longer stored in your home directory. Note that you **do not have to stop the service before upgrading**. Upgrading to v2 will handle that automatically.


### Installing Docker

Before installing the Smart Node, you'll need to have Docker's apt repository set up so your system can install Docker. If you have it set up already (i.e., from Smart Node v1), you can skip this step.

Start by following [Docker's installation instructions](https://docs.docker.com/engine/install/) to install it for your operating system.

Next, add your user to the group of Docker administrators:
```
sudo usermod -aG docker $USER
```

Finally, exit the terminal session and start a new one (log out and back in or close and re-open SSH) for the new permissions to take effect.


### Installing Official Releases via the Package Manager

Smart Node v2 introduces support for the `dpkg` package manager, meaning it can be installed via `apt` on Debian-based systems as with other system software. Rocket Pool uses [Packagecloud](https://packagecloud.io/) to host the Smart Node packages.

The package includes everything you need to run, including the CLI and other installation files. If you're installing this way, you **do not** need to manually download the CLI or run `rocketpool service install` afterwards.


#### Installing for the First Time

1. Update the system packages:
    ```
    sudo apt update
    ```
2. Install some dependencies:
    ```
    sudo apt-get install curl gnupg apt-transport-https ca-certificates
    ```
3. Download the Smart Node repo key:
    ```
    sudo install -m 0755 -d /etc/apt/keyrings
    ```
    ```
    sudo curl -fsSL https://packagecloud.io/rocketpool/smartnode/gpgkey -o /etc/apt/keyrings/smartnode.asc
    ```
4. Add the Smart Node repo to your list of repositories:
    ```
    sudo tee -a /etc/apt/sources.list.d/smartnode.list << EOF
    deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/smartnode.asc] https://packagecloud.io/rocketpool/smartnode/any/ any main 
    deb-src [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/smartnode.asc] https://packagecloud.io/rocketpool/smartnode/any/ any main
    EOF
    ```
5. Install the Smart Node:
    ```
    sudo apt update && sudo apt install rocketpool
    ```


#### Updating an Existing Installation

If you've already installed the Smart Node package, it will be included with the other system updates any time you do an update check:
```
sudo apt update && sudo apt dist-upgrade -y && sudo apt autoremove -y
```


### Installing via `rocketpool service install` and GitHub

This method was used by Smart Node v1, and is still available in v2. It is the "general purpose" method can be used for any release, including development prototypes, and will work on any system that Rocket Pool supports. At a high level it involves manually downloading the CLI, then running a command with it to install the rest of the service.

1. Download the CLI binary for your architecture from [the Smart Node repository](https://github.com/rocket-pool/smartnode/releases) and install it to `/usr/bin/rocketpool`.
    - Note this is the `smartnode` repository, **not the** `smartnode-install` repository like you are probably used to. Smart Node v2 has the `smartnode-install` artifacts rolled into it, and no longer uses that repository.
    - The package manager installers will install the CLI to `/usr/bin/rocketpool` so for consistency we recommend you put it there as well, but really it can go anywhere that's in your system path. v1 used `~/bin/rocketpool`, for example.
2. Run `rocketpool service install` if you're installing it for the first time, or `rocketpool service install -d` if you're upgrading an installation.
    - Note the install script now emulates the package manager installers, and will require elevated permissions to run (i.e., `sudo` or `doas`).


### Installing via `rocketpool service install` without GitHub

If you'd like to use the CLI-based installer, but don't have access to GitHub, you can save the relevant files to disk and install using them instead.

1. Download the CLI binary (see instructions above).
2. Download `install.sh` and `smartnode-install.tar.xz` from GitHub and save them to disk wherever you want (e.g., `~/Downloads` or `/tmp`). Note that both files *must* be in the same directory.
3. Navigate to the folder with the installer files and run `rocketpool service install -l` if you're installing it for the first time, or `rocketpool service install -d -l` if you're upgrading an installation.
    - Note the install script now emulates the package manager installers, and will require elevated permissions to run (i.e., `sudo` or `doas`).



### Installing Development Releases via the Package Manager

Development packages are uploaded with the other development artifacts on GitHub.

1. Remove any old Smart Node installation:
    - Note this **will not** remove your data directory, your wallet, your validator keys, or any of your configuration files stored in your user / data directories (default `~/.rocketpool` and `~/.rocketpool/data`). It will *only* remove the CLI and supporting install files.
    ```
    sudo apt purge rocketpool
    ```
2. Download the Smart Node installer for your CPU architecture (e.g., `https://github.com/rocket-pool/smartnode/releases/download/v2.0.0-dev/rocketpool_2.0.0_amd64.deb`).
3. Install the new package *from the local file path*:
    ```
    sudo apt install ./rocketpool_2.0.0_amd64.deb
    ```
4. Don't forget to include `-u` when running `rocketpool service config` to emulate a package upgrade!


## Installing v2 - Native Mode

Prior to installation, please note that Smart Node v2 will **only work with the Rocket Pool Houston upgrade**. It will not work with Atlas or any previous Rocket Pool protocol version.


### **IMPORTANT:** Migrating from Smart Node v1

If you have Smart Node v1 already installed on your machine, you will need to do a little bit of cleanup before installing v2.

First, **back up your existing Rocket Pool directory (`~/.rocketpool` by default)** somewhere safe, just in case. Next, run the following command:
```
rm -rf ~/bin/rocketpool ~/.rocketpool/scripts ~/.rocketpool/templates ~/.rocketpool/prometheus.tmpl
```
This will delete the old v1 CLI and some accompanying installation files that are no longer stored in your home directory.

Now, delete the Watchtower service as it's no longer needed:
```
sudo systemctl stop rp-watchtower

sudo systemctl disable rp-watchtower

sudo rm -f /etc/systemd/system/rp-watchtower.service
```

Next, follow the instructions below.


### Installing Native Mode

The Native mode installation process is quite similar to [the process used in v1](https://docs.rocketpool.net/guides/node/native) so we recommend you use that as a starting point.

The differences are as follows:

1. You do *not* need to create a service for the Watchtower. You only need to create one for the Node. In v2, the Watchtower has been rolled into the Node.
2. The `ExecStart` portion of the `rp-node` service definition is now:
    ```
    /usr/local/bin/rocketpoold -u /srv/rocketpool
    ```
3. Whenever you run the CLI, you should use the `-n` flag to specify native mode (i.e. `rocketpool -n service config`). If you previously used the `-d` flag, it has been removed. We recommend setting the alias `rp="rocketpool -n -c /srv/rocketpool"` now for convenience.
4. When running `rp service config`, make sure the paths to the `VC Restart Script` and the `Validator Stop Command` point to the correct locations on your filesystem as the defaults have changed in v2.


## Running v2 as a Node Operator

Running the Smart Node is, for all practical purposes, the same as it was in `v1`. The `rocketpool service start` command will still initialize Docker compose with all of the latest container definition files and begin the service, `rocketpool service stop` will still shut it down, and so on. The primary differences are:

- You can now opt into 
- The `rocketpool_api` and `rocketpool_watchtower` containers have been removed
- There's a new `Logging` section in the service config TUI, and some new log commands
    - Use `rocketpool service node-logs api` to view the new API logs
    - Use `rocketpool service node-logs tasks` to view the node task loop logs (previously `rocketpool service logs node`)
    - Use `rocketpool service node-logs watchtower` to view the watchtower task loop logs (`rocketpool service logs watchtower`)
- The "non-modifiable" files like Docker compose templates and scripts are now in `/usr/share/rocketpool` instead of your user home directory (though personal files like overrides are still in your home directory)
- The CLI (if installed via the package manager) is now at `/usr/bin/rocketpool` instead of `~/bin/rocketpool`
- Some CLI commands have moved and/or have new flags (see the overview section above)
- Commands that involve selecting multiple items (such as distributing minipool balances) will now let you select arbitrary options, and submit all of the transactions at once. The overall flow will feel much faster.

Everything else is unchanged, and your experience should be quite familar if you were a v1 node operator.


## Building v2

The Smart Node repository consists of the following artifacts:
- The Smart Node CLI, `rocketpool`, inside the `rocketpool-cli` folder
    - This can be built for local use by navigating to the folder and running `go build`.
- The Smart Node Daemon, `rocketpoold`, inside the `rocketpool-daemon` folder
    - This can be built for local use by navigating to the folder and running `go build`.
- The `docker` folder, with:
    - A Docker-based build system for making the CLI binaries via a Debian container (`cli.dockerfile`)
    - A Docker-based build system for making the Daemon binaries via a Debian container (`daemon-build.dockerfile`)
    - A Docker container with the `rocketpoold` daemon binary and supporting filesystem (`daemon.dockerfile`)
- The `install` folder, with:
    - All of the "installer artifact" files that will be deployed when the Smart Node is installed, in `deploy`
    - The install script used by the `service install` command, as `install.sh`
    - The package manager package build files and Docker-based build contexts, in `packages` 

The Smart Node and accompanying artifacts can be built via the build script included in the repository, `build.sh` (eventually to be replaced by a more traditional build system, such as a Makefile). The build script's help text explains its usage for constructing various artifacts.

To build the daemon and package manager artifacts, we *strongly* encourage you to use the build script instead of attempting to build them manually due to dependencies and the highly portable glibc version used by the `debian/bookworm` build context.


## Components (for Reference)

This is a breakdown of the different components involved in Smart Node v2.


### Node Manager Core

Smart Node v2 is built on top of the [Node Manager Core](https://github.com/rocket-pool/node-manager-core), a general purpose framework for constructing Ethereum node management software. It provides Execution client configuration, Beacon Node configuration, validator key management across multiple clients, a standardized API client/server system, logging functionality, and wallet management services among some other useful utilities.


### rocketpool-go

Underlying the Smart Node is a library called [`rocketpool-go`](https://github.com/rocket-pool/rocketpool-go/tree/tx-refactor). `rocketpool-go` is a binding for the [Rocket Pool smart contracts](https://github.com/rocket-pool/rocketpool) on the Ethereum execution layer. It can be used to easily interact with them in `go` programs, hence the name.

In v1, `rocketpool-go` was a fairly low-level binding to the contracts; its functions were package-level and directly bound the contract functions, taking in and returning the same types. The (mostly) kept the same structure as the contracs, providing a 1-1 mapping of contract to go file.

In v2, the library has been completely rewritten. It is now a high-level binding with a completely different structure from the actual contracts. Instead, it is based around the notion of logical "managers" for various aspects of the protocol (such as a node manager, a minipool manager, and a Protocol DAO manager) and "entities" for things that can be instantiated (such as nodes, minipools, and proposals). Each of these wraps one or more contracts to provide the corresponding functonality that the logical manager or entity should "own" in typical object-oriented fashion, as many of these methods belong to different contracts due to Solidity size restrictions and implementation decisions.

For example, a logical "node" in the Rocket Pool network has many properties that describe it. These properties are distributed via views (Solidity getters) in the `RocketNodeManager`, `RocketMinipoolManager`, `RocketNodeStaking`, `RocketNodeDeposit`, `RocketNetworkVoting`, `RocketMinipoolFactory`, and `RocketNodeDistributorFactory` contracts. The views in question typically take a node's address as a parameter to provide the corresponding result for that node.

 Rather than implement a direct go binding for each contract and let the user call the views they want, v2's `rocketpool-go` introduces [a single `Node` struct](https://github.com/rocket-pool/rocketpool-go/blob/89c7a07299e833e2aecccba280ce8b985c8bcf8d/node/node.go#L22) that contains the relevant functionality from each of those contracts as struct fields, rather than getters. Each field can be added to a multicall instance, which will populate all of them with the proper on-chain data at once. They can then be accessed after the multicall execution to retrieve the results.


### The Daemon

The daemon is the Smart Node's persistent service that manages the Rocket Pool node it's installed on. In Docker or Hybrid mode, it runs as a Docker container. In Native mode, it runs however the user decides to run it (typically as a `systemd` service). The daemon provides three key subroutines: the API server, the Node task loop, and the Watchtower task loop.


#### The API Server

The API Server manifests as a conventional HTTP server. The server itself comes from the Node Manager Core, and the Smart Node implements the specific API routes and handlers relevant to Rocket Pool node operation. The top-level domain is simply `rocketpool`. Routes within it are first assigned an API version: for this release, everything resides in `api/v1`. Each route is represented by a handler, which provides the name (path) of the route, and a list of subroutes for individual tasks underneath it.

For example, the [network stats route](https://github.com/rocket-pool/smartnode/blob/v2/rocketpool-daemon/api/network/stats.go) returns statistics about the Rocket Pool network as a whole. Accessing it is done by sending an HTTP requests to the Unix socket maintained by the API server (defaults to `~/.rocketpool/rocketpool-cli.sock`) with the following URL:

    http://rocketpool/api/v1/network/stats

Each subroute is represented by a single go file holding a context to execute that function, and each overall route is represented by a `handler.go` file within the corresponding package.

Contexts will accept either `GET` or `POST` as a request method, depending on the context. Requests are all handled in individual goroutines, so the results of one don't impact another.

For a full breakdown of API routes exposed by the daemon see [this TBD link here](tbd).

The logs for this loop can be found in `~/.rocketpool/logs/api.log`, and viewed via `rocketpool s nl api`. The source of the log is included in the `origin` attribute per-line, which is `cli` for CLI requests and `net` for web-based requests (to be implemented later).


#### The Node Task Loop

The Node task loop is a repeating routine that automatically scans for and resolves certain condiditons that require intervention. These triggers can stem form both your local node filesystem and the contract state on the Execution layer. It includes tasks like:
- Verifying your fee recipient is correct based on your node address and your Smoothing Pool opt-in status
- Staking minipools after they've passed the prelaunch scrub check, completing their deposits
- Promoting solo-staker-migrated validators into minipools after they've passed the prelaunch scrub check
- Completing the bond reduction process to convert 16-ETH minipools into 8-ETH ones after they've passed the scrub check
- Downloading missing rewards tree files
- Verifying and defending on-chain Protocol DAO proposals

The logs for this loop can be found in `~/.rocketpool/logs/tasks.log`, and viewed via `rocketpool s nl tasks`.


#### The Watchtower Task Loop

The watchtower task loop is a repeating routine primarily used by the Oracle DAO for performing checks and running transactions that ensure the safety of the Rocket Pool network itself. Examples include:
- Scrubbing new minipools have been exploited by the [withdrawal credentials exploit](https://github.com/rocket-pool/rocketpool-research/blob/master/Reports/withdrawal-creds-exploit.md)
- Scrubbing solo migrations or bond reductions that have violated the rules
- Submitting the routine network balance (rETH value) updates and ETH/RPL price ratio
- Calculating, creating, and submitting the rewards tree at the end of each interval

Non-Oracle DAO operators can largely ignore the watchtower unless they intend to generate their own rewards files instead of using the ones created by the Oracle DAO, as that is also a watchtower duty.

The logs for this loop can be found in `~/.rocketpool/logs/watchtower.log`, and viewed via `rocketpool s nl watchtower`.


### The CLI

The Smart Node comes with a CLI tool called `rocketpool`. It is essentially a frontend to the daemon and allows the user to observe, tailor, and otherwise interact with their node. It is also responsible for constructing and validating the Smart Node's configuration file (`user-settings.yml`), initializing the Docker Compose template files with the proper runtime values, and interacting with Docker itself to start and stop services, provide logs, and so on.
